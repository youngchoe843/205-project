{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull and analyze Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis of people tweeting about Trump\n",
    "Compare with Approval rating?\n",
    "Effect on stock price of Companies mentioned in tweets\n",
    "Watch tweets that mention companies, pull market data\n",
    "Watch tweets that mention an industry or sector, pull market data\n",
    "Sentiment analysis around travel ban\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from twitter import *\n",
    "import json\n",
    "import os,sys, time\n",
    "from os import path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Set up twitter configuration\n",
    "config = {}\n",
    "localPath = \"/Users/erikaananda/Documents/MIDS/W205/admin/CourseProject/\"\n",
    "configFile = localPath  + \"config.py\"\n",
    "outFile = (localPath + \"Tweets/\" + str(time.time()) + \".txt\")\n",
    "\n",
    "with open(configFile) as f:\n",
    "    code = compile(f.read(), configFile, 'exec')\n",
    "    exec(code, config)\n",
    "\n",
    "#print(outFile)\n",
    "#print(config[\"access_key\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "travel ban|2017-03-04 17:20:36|badbuddhist01|b'RT @DefineAmerican: DHS memos conclude that radicalization occurs long after immigration, making \"heavy-vetting\" unnecessary. https://t.co/\\xe2\\x80\\xa6'|838076724784984064|838076596237918208\n",
      "travel ban|2017-03-04 17:20:25|Dodarey|b'RT @AnnCoulter: Banned immigrant let in by Sen. Chuck Schumer accused of sexual assault on 12 yr-old girl, days after arriving - https://t.\\xe2\\x80\\xa6'|838076677154553861|837990156456116225\n",
      "travel ban|2017-03-04 17:20:12|robinjb73|b'RT @AnnCoulter: Banned immigrant let in by Sen. Chuck Schumer accused of sexual assault on 12 yr-old girl, days after arriving - https://t.\\xe2\\x80\\xa6'|838076622947274753|837990156456116225\n",
      "travel ban|2017-03-04 17:20:09|aemdee|b'RT @PeterFeaman: Schumer pulled strings to get athlete past Trump\\xe2\\x80\\x99s travel ban; guy gets charged sexually abusing a child https://t.co/OGCV\\xe2\\x80\\xa6'|838076610951659524|838074584431636481\n",
      "travel ban|2017-03-04 17:20:05|DefineAmerican|b'DHS memos conclude that radicalization occurs long after immigration, making \"heavy-vetting\" unnecessary. https://t.co/E0xg5KbKJ8'|838076596237918208|0\n",
      "travel ban|2017-03-04 17:20:02|janetpeiser|b'RT @DailyCaller: Over 4300 Refugees Have Arrived In The US Since Judge Blocked Trump\\xe2\\x80\\x99s Travel Ban https://t.co/nOovTMhOxd https://t.co/UEA3\\xe2\\x80\\xa6'|838076581440552960|837533343994408960\n",
      "travel ban|2017-03-04 17:20:00|Tracey4America|b\"@NolteNC  Axlerod clearly didn't see the 9th circuit travel ban ruling \\xf0\\x9f\\x98\\x82\\xf0\\x9f\\x98\\x82\"|838076573743894529|0\n",
      "travel ban|2017-03-04 17:19:45|OmegaMan58|b'RT @AnnCoulter: Banned immigrant let in by Sen. Chuck Schumer accused of sexual assault on 12 yr-old girl, days after arriving - https://t.\\xe2\\x80\\xa6'|838076511915630592|837990156456116225\n",
      "travel ban|2017-03-04 17:19:42|owlbelief|b'RT @AdvertisingLaw: More Than 4,300 Refugees Have Arrived In The US Since Judge Blocked Trump\\xe2\\x80\\x99s Travel Ban | The Daily Caller https://t.co/\\xe2\\x80\\xa6'|838076498556911617|838072336389668864\n",
      "travel ban|2017-03-04 17:19:39|realEricTyson|b'RT @The_Trump_Train: Muslim man effected by travel ban denied visa until Schumer intervened. Two days go, he was arrested for sexual assaul\\xe2\\x80\\xa6'|838076483730083844|837805202141036544\n",
      "travel ban|2017-03-04 17:19:34|Spiritof1642|b'RT @TEN_GOP: BREAKING: Muslim effected by travel ban and denied visa until Schumer intervened, arrested for sexual assault on children. #Li\\xe2\\x80\\xa6'|838076463450480641|837812265571115008\n",
      "travel ban|2017-03-04 17:19:33|tofulew|b'RT @HackReactor: We have reserved a full scholarship for a person affected by the recent travel ban: #inclusitivioty #morethancoding  https\\xe2\\x80\\xa6'|838076460510416898|831530954200141824\n",
      "travel ban|2017-03-04 17:19:31|blakestacey|b\"How the fallout from Trump's travel ban is reshaping science https://t.co/05LlKuoJUK\"|838076453984022529|0\n",
      "travel ban|2017-03-04 17:19:28|samsmd|b'RT @AnnCoulter: Banned immigrant let in by Sen. Chuck Schumer accused of sexual assault on 12 yr-old girl, days after arriving - https://t.\\xe2\\x80\\xa6'|838076438649667586|837990156456116225\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3137"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new figure and set the figsize argument so we get square-ish plots of the 4 features.\n",
    "search_string = \"travel ban\"\n",
    "twitter = Twitter(auth = OAuth(config[\"access_key\"], config[\"access_secret\"], config[\"consumer_key\"], config[\"consumer_secret\"]))\n",
    "query = twitter.search.tweets(q = search_string, lang = 'en')\n",
    "#print(query)\n",
    "\n",
    "joined_str = \"\"\n",
    "for result in query[\"statuses\"]:\n",
    "    emp_time = time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(str(result[\"created_at\"]),'%a %b %d %H:%M:%S +0000 %Y'))\n",
    "    joined_str += search_string + \"|\"\n",
    "    joined_str += str(emp_time) + \"|\"\n",
    "    joined_str += str(result[\"user\"][\"screen_name\"]) + \"|\" \n",
    "    joined_str += str((result[\"text\"].strip().replace('\\n', ' ').replace('\\r', '')).encode('utf8')) + \"|\"\n",
    "    joined_str += str(result[\"id_str\"]) + \"|\"\n",
    "    try: \n",
    "        retweetID = str(result[\"retweeted_status\"][\"id\"])\n",
    "    except: \n",
    "        retweetID = \"0\"\n",
    "    joined_str += retweetID + \"\\n\"\n",
    "print(joined_str)\n",
    "tFile = open(outFile, 'w')\n",
    "#tFile.write(joined_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%pyspark\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import explode\n",
    "sqlContext = SQLContext(sc)\n",
    "sqlContext = sqlc\n",
    "\n",
    "testrdd = sc.textFile('C:/Users/nkavumpu/Desktop/My/Visa/Projects/Social Media sentiments/python-twitter-examples-master/Tweet*.txt')\n",
    "\n",
    "testrdduniq = testrdd.distinct()\n",
    "import os\n",
    "import nltk\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer # requires twython?\n",
    "from nltk.sentiment.util import *\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "tweetpair = testrdduniq.map(lambda x: x.split(\"|\")).map(lambda x: (x[3],(x[1],x[2],x[0])))\n",
    "scorerdd = testrdduniq.map(lambda x: x.split('|')).map(lambda x: (x[3],sid.polarity_scores(x[3]))) #working 2\n",
    "\n",
    "tweetpair.persist()\n",
    "scorerdd.persist()\n",
    "\n",
    "\n",
    "tweetpairtemp = tweetpair.map(lambda p: Row(tweetblob=p[0] , time = p[1][0] , userid = p[1][1], searchterm = p[1][2])) #working\n",
    "# Infer the schema, and register the DataFrame as a table.\n",
    "tweetpairDF = sqlContext.createDataFrame(tweetpairtemp)#working\n",
    "tweetpairDF.persist()\n",
    "tweetpairDF.registerTempTable(\"tweetpair\")#working\n",
    "#r = tweetpairDF.take(5)\n",
    "#print r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \n",
    "schema = StructType([StructField(\"tweetblob\", StringType(), True),\n",
    "         StructField(\"score\", MapType(StringType(), StringType(), True))\n",
    "]) \n",
    "tweetscoretemp = sqlContext.createDataFrame(scorerdd, schema)\n",
    "tweetscoreDF = tweetscoretemp.select(tweetscoretemp.tweetblob,explode(tweetscoretemp.score))\n",
    "tweetscoreDF.persist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "%sql\n",
    "select \n",
    "-- distinct s.value from tweetscore s\n",
    "t.searchterm,t.tweetblob,s.key,s.value,t.userid,substr(t.time,1,13) as tm_hr \n",
    "from tweetscore s\n",
    "join tweetpair t on t.tweetblob = s.tweetblob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
